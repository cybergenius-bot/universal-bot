import os
import io
import asyncio
import logging
import subprocess
import base64
from typing import Optional, List
from contextlib import asynccontextmanager
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, ContextTypes, filters
logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(name)s %(message)s")
logger = logging.getLogger("bot")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "")
TELEGRAM_WEBHOOK_SECRET = os.getenv("TELEGRAM_WEBHOOK_SECRET", "")
PUBLIC_BASE_URL = os.getenv("PUBLIC_BASE_URL", "").rstrip("/")
WEBHOOK_PATH = "/telegram"
WEBHOOK_URL = f"{PUBLIC_BASE_URL}{WEBHOOK_PATH}" if PUBLIC_BASE_URL else ""
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
OPENAI_TEXT_MODEL = os.getenv("OPENAI_TEXT_MODEL", "gpt-4o-mini")
OPENAI_VISION_MODEL = os.getenv("OPENAI_VISION_MODEL", "gpt-4o-mini")
OPENAI_WHISPER_MODEL = os.getenv("OPENAI_WHISPER_MODEL", "whisper-1")
try:
from openai import OpenAI
openai_client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None
except Exception as e:
logger.warning("OpenAI SDK init warn: %s", e)
openai_client = None
application: Optional[Application] = None
class NamedBytesIO(io.BytesIO):
def __init__(self, data: bytes, name: str):
    super().__init__(data); self.name = name
def chunk_text(text: str, limit: int = 3500) -> List[str]:
chunks: List[str] = []; current = []; size = 0
for line in text.splitlines(keepends=True):
    if size + len(line) > limit and current:
        chunks.append("".join(current)); current, size = [], 0
    current.append(line); size += len(line)
if current: chunks.append("".join(current))
return chunks or [text]
async def send_long_text(update: Update, text: str):
for part in chunk_text(text, 3500):
    await update.message.reply_text(part, disable_web_page_preview=True)
async def tg_download_bytes(bot, file_id: str) -> bytes:
tg_file = await bot.get_file(file_id); bio = io.BytesIO()
await tg_file.download_to_memory(out=bio); return bio.getvalue()
def ffmpeg_to_wav_sync(src: bytes) -> bytes:
p = subprocess.run(["ffmpeg","-loglevel","error","-y","-i","pipe:0","-vn","-ac","1","-ar","16000","-f","wav","pipe:1"],
                   input=src, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
return p.stdout
def extract_keyframes_sync(src: bytes, frames: int = 3, scale_width: int = 640) -> List[bytes]:
p = subprocess.run(["ffmpeg","-loglevel","error","-y","-i","pipe:0","-vf",f"fps=1,scale={scale_width}:-1",
                    "-vframes",str(frames),"-f","image2pipe","-vcodec","mjpeg","pipe:1"],
                   input=src, stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)
data = p.stdout; imgs = []; SOI = b"\xff\xd8"; EOI = b"\xff\xd9"; i = 0
while True:
    s = data.find(SOI, i); 
    if s == -1: break
    e = data.find(EOI, s); 
    if e == -1: break
    imgs.append(data[s:e+2]); i = e + 2
return imgs[:frames]
def whisper_sync(data: bytes, name: str, lang: Optional[str] = "ru") -> str:
if not openai_client: raise RuntimeError("OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω –∏–ª–∏ OpenAI –∫–ª–∏–µ–Ω—Ç –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
text = openai_client.audio.transcriptions.create(model=OPENAI_WHISPER_MODEL,
                                                 file=NamedBytesIO(data, name),
                                                 response_format="text", language=lang or "ru",
                                                 temperature=0)
return text
def _data_url(image_bytes: bytes) -> str:
return "data:image/jpeg;base64," + base64.b64encode(image_bytes).decode("ascii")
def llm_generate_sync(prompt: str, system: str = "–¢—ã –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω—ã–π –∏ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.",
                  max_tokens: int = 1600, temperature: float = 0.7) -> str:
if not openai_client: raise RuntimeError("OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω, —Ç–µ–∫—Å—Ç–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.")
resp = openai_client.chat.completions.create(model=OPENAI_TEXT_MODEL,
    messages=[{"role":"system","content":system},{"role":"user","content":prompt}],
    max_tokens=max_tokens, temperature=temperature)
return (resp.choices[0].message.content or "").strip()
def vision_analyze_sync(image_bytes: bytes, question: str = "–û–ø–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω–æ, —á—Ç–æ –Ω–∞ —Ñ–æ—Ç–æ, –∏ –∏–∑–≤–ª–µ–∫–∏ –≤–∞–∂–Ω—ã–π —Ç–µ–∫—Å—Ç.") -> str:
if not openai_client: raise RuntimeError("OPENAI_API_KEY –Ω–µ –∑–∞–¥–∞–Ω, –≤–∏–∑—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
data_url = _data_url(image_bytes)
resp = openai_client.chat.completions.create(model=OPENAI_VISION_MODEL,
    messages=[{"role":"system","content":"–¢—ã –≤–∏–∑—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫. –ö—Ä–∞—Ç–∫–æ –æ–±—ä–µ–∫—Ç—ã, –∑–∞—Ç–µ–º –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏ –≤—ã–≤–æ–¥—ã. –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç ‚Äî –ø—Ä–æ—Ü–∏—Ç–∏—Ä—É–π (OCR)."},
              {"role":"user","content":[{"type":"text","text":question},{"type":"image_url","image_url":{"url":data_url}}]}],
    max_tokens=900, temperature=0.5)
return (resp.choices[0].message.content or "").strip()
async def cmd_start(update: Update, context: ContextTypes.DEFAULT_TYPE):
await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! üëã –Ø —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ò–ò‚Äë–±–æ—Ç.\n–£–º–µ—é: —Ç–µ–∫—Å—Ç (–ø–æ–¥—Ä–æ–±–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã –∏ Stories), –≥–æ–ª–æ—Å/–∞—É–¥–∏–æ (—Ä–∞—Å–ø–æ–∑–Ω–∞—é), —Ñ–æ—Ç–æ/–≤–∏–¥–µ–æ (–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é).\n–ö–æ–º–∞–Ω–¥—ã: /help /story /pricing /buy /ref /status")
async def cmd_help(update: Update, context: ContextTypes.DEFAULT_TYPE):
await update.message.reply_text("–°–ø—Ä–∞–≤–∫–∞:\n‚Ä¢ –ü–∏—à–∏—Ç–µ –≤–æ–ø—Ä–æ—Å ‚Äî –æ—Ç–≤–µ—á—É —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç–æ\n‚Ä¢ –ì–æ–ª–æ—Å/–∞—É–¥–∏–æ ‚Äî —Ä–∞—Å–ø–æ–∑–Ω–∞—é —Ç–µ–∫—Å—Ç\n‚Ä¢ –§–æ—Ç–æ ‚Äî –æ–ø–∏—à—É –∏ –∏–∑–≤–ª–µ–∫—É —Ç–µ–∫—Å—Ç\n‚Ä¢ –í–∏–¥–µ–æ ‚Äî –∏–∑–≤–ª–µ–∫—É –∞—É–¥–∏–æ –∏ –∫–∞–¥—Ä—ã, —Å–¥–µ–ª–∞—é –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ\n‚Ä¢ /story <—Ç–µ–º–∞> ‚Äî –Ω–∞–ø–∏—à—É –æ–±—ä—ë–º–Ω—ã–π —Ä–∞—Å—Å–∫–∞–∑")
async def cmd_pricing(update: Update, context: ContextTypes.DEFAULT_TYPE):
await update.message.reply_text("–¢–∞—Ä–∏—Ñ—ã: Free 5 Q, $10 ‚Üí 20 Q, $30 ‚Üí 200 Q, $50 ‚Üí –±–µ–∑–ª–∏–º–∏—Ç/–º–µ—Å.")
async def cmd_buy(update: Update, context: ContextTypes.DEFAULT_TYPE):
await update.message.reply_text("–ü–æ–∫—É–ø–∫–∞ —Å–∫–æ—Ä–æ. –í —Ä–∞–±–æ—Ç–µ PayPal/Stripe/Telegram Stars.")
async def cmd_ref(update: Update, context: ContextTypes.DEFAULT_TYPE):
me = await context.bot.get_me(); user = update.effective_user
ref_param = f"ref{user.id}" if user else "ref0"
await update.message.reply_text(f"–í–∞—à–∞ —Ä–µ—Ñ. —Å—Å—ã–ª–∫–∞: https://t.me/{me.username}?start={ref_param}")
async def cmd_status(update: Update, context: ContextTypes.DEFAULT_TYPE):
await update.message.reply_text("–°—Ç–∞—Ç—É—Å: –æ–Ω–ª–∞–π–Ω ‚úÖ")
async def cmd_story(update: Update, context: ContextTypes.DEFAULT_TYPE):
if not update.message: return
topic = (update.message.text or "").split(" ", 1)
prompt = topic[1].strip() if len(topic) > 1 else "–°–≤–æ–±–æ–¥–Ω–∞—è —Ç–µ–º–∞. –ù–∞–ø–∏—à–∏ –≤–¥–æ—Ö–Ω–æ–≤–ª—è—é—â–∏–π —Ä–∞—Å—Å–∫–∞–∑ –Ω–∞ 1200‚Äì1800 —Å–ª–æ–≤."
try:
    text = await asyncio.to_thread(llm_generate_sync,
        f"–ù–∞–ø–∏—à–∏ —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ä–∞—Å—Å–∫–∞–∑ —Å —è—Ä–∫–∏–º–∏ —Å—Ü–µ–Ω–∞–º–∏, –¥–∏–∞–ª–æ–≥–∞–º–∏, –¥–∏–Ω–∞–º–∏–∫–æ–π, —Å–∏–ª—å–Ω–æ–π –∫–æ–Ω—Ü–æ–≤–∫–æ–π. –¢–µ–º–∞/–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è: {prompt}",
        "–¢—ã –æ–ø—ã—Ç–Ω—ã–π –ø–∏—Å–∞—Ç–µ–ª—å. –ü–∏—à–∏ –æ–±—Ä–∞–∑–Ω–æ, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–æ, —Å –ª–æ–≥–∏–∫–æ–π –∏ —Å—Ç–∏–ª—å–Ω—ã–º–∏ –ø–µ—Ä–µ—Ö–æ–¥–∞–º–∏.",
        max_tokens=2000, temperature=0.85)
    await send_long_text(update, text or "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ä–∞—Å—Å–∫–∞–∑.")
except Exception as e:
    logger.exception("Story error: %s", e)
    await update.message.reply_text("–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–∞—Å—Å–∫–∞–∑–∞.")
async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
if not update.message or not update.message.text: return
user_text = update.message.text.strip(); lower = user_text.lower()
if lower.startswith(("story:", "–∏—Å—Ç–æ—Ä–∏—è:", "—Ä–∞—Å—Å–∫–∞–∑:")):
    update.message.text = "/story " + user_text.split(":", 1)[1]; return await cmd_story(update, context)
try:
    text = await asyncio.to_thread(llm_generate_sync,
        f"–û—Ç–≤–µ—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–¥—Ä–æ–±–Ω–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–æ. –í–æ–ø—Ä–æ—Å: {user_text}",
        "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç‚Äë–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –î–∞—ë—à—å –æ–±—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã–µ, –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã.",
        max_tokens=1400, temperature=0.65)
    await send_long_text(update, text or "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç.")
except Exception as e:
    logger.exception("Text LLM error: %s", e)
    await update.message.reply_text("–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞.")
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
if not update.message or not update.message.voice: return
try:
    ogg = await tg_download_bytes(context.bot, update.message.voice.file_id)
    try:
        text = await asyncio.to_thread(whisper_sync, ogg, "audio.ogg", "ru")
    except Exception as e:
        logger.warning("OGG‚ÜíWhisper failed, try ffmpeg‚ÜíWAV: %s", e)
        wav = await asyncio.to_thread(ffmpeg_to_wav_sync, ogg)
        text = await asyncio.to_thread(whisper_sync, wav, "audio.wav", "ru")
    text = (text or "").strip()
    if not text: return await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å.")
    answer = await asyncio.to_thread(llm_generate_sync,
        f"–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {text}",
        "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç‚Äë–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –î–∞—ë—à—å –æ–±—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã.", max_tokens=1000, temperature=0.6)
    await send_long_text(update, answer or text)
except Exception as e:
    logger.exception("Voice STT/LLM error: %s", e)
    await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
async def handle_audio(update: Update, context: ContextTypes.DEFAULT_TYPE):
if not update.message or not update.message.audio: return
try:
    b = await tg_download_bytes(context.bot, update.message.audio.file_id)
    try:
        name = (update.message.audio.file_name or "audio").lower()
        txt = await asyncio.to_thread(whisper_sync, b, name, "ru")
    except Exception:
        wav = await asyncio.to_thread(ffmpeg_to_wav_sync, b)
        txt = await asyncio.to_thread(whisper_sync, wav, "audio.wav", "ru")
    txt = (txt or "").strip()
    if not txt: return await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∞—É–¥–∏–æ.")
    answer = await asyncio.to_thread(llm_generate_sync,
        f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–∏—Å–ª–∞–ª –∞—É–¥–∏–æ. –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {txt}. –î–∞–π —Ä–∞–∑–≤—ë—Ä–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç.",
        max_tokens=1000, temperature=0.6)
    await send_long_text(update, answer or txt)
except Exception as e:
    logger.exception("Audio STT/LLM error: %s", e)
    await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∞—É–¥–∏–æ.")
async def handle_video_note(update: Update, context: ContextTypes.DEFAULT_TYPE):
if not update.message or not update.message.video_note: return
try:
    mp4 = await tg_download_bytes(context.bot, update.message.video_note.file_id)
    wav = await asyncio.to_thread(ffmpeg_to_wav_sync, mp4)
    txt = await asyncio.to_thread(whisper_sync, wav, "circle.wav", "ru")
    txt = (txt or "").strip()
    if not txt: return await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∫—Ä—É–∂–æ–∫.")
    summary = await asyncio.to_thread(llm_generate_sync, f"–°—É–º–º–∞—Ä–∏–∑–∏—Ä—É–π –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {txt}", max_tokens=800)
    await send_long_text(update, summary or txt)
except Exception as e:
    logger.exception("VideoNote STT/LLM error: %s", e)
    await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∫—Ä—É–∂–æ–∫.")
async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
if not update.message or not update.message.photo: return
try:
    best = update.message.photo[-1]
    b = await tg_download_bytes(context.bot, best.file_id)
    analysis = await asyncio.to_thread(vision_analyze_sync, b, "–û–ø–∏—à–∏ –ø—Ä–µ–¥–º–µ—Ç—ã, –∫–æ–Ω—Ç–µ–∫—Å—Ç; –∏–∑–≤–ª–µ–∫–∏ —Ç–µ–∫—Å—Ç (–µ—Å–ª–∏ –µ—Å—Ç—å); —Å–¥–µ–ª–∞–π –≤—ã–≤–æ–¥—ã.")
    await send_long_text(update, analysis or "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ–æ—Ç–æ.")
except Exception as e:
    logger.exception("Photo vision error: %s", e)
    await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–æ—Ç–æ.")
async def handle_video(update: Update, context: ContextTypes.DEFAULT_TYPE):
if not update.message or not update.message.video: return
try:
    vid = await tg_download_bytes(context.bot, update.message.video.file_id)
    wav = await asyncio.to_thread(ffmpeg_to_wav_sync, vid)
    transcript = await asyncio.to_thread(whisper_sync, wav, "video.wav", "ru")
    transcript = (transcript or "").strip()
    summary = ""
    if transcript:
        summary = await asyncio.to_thread(llm_generate_sync, f"–ö—Ä–∞—Ç–∫–æ –ø–µ—Ä–µ—Å–∫–∞–∂–∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –≤–∏–¥–µ–æ (–ø–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç—É): {transcript}", max_tokens=900)
    frames = await asyncio.to_thread(extract_keyframes_sync, vid, 3, 640)
    vision_parts: List[str] = []
    for i, img in enumerate(frames, 1):
        try:
            part = await asyncio.to_thread(vision_analyze_sync, img, f"–ö–∞–¥—Ä {i}. –ö—Ä–∞—Ç–∫–æ: —á—Ç–æ –≤–∏–¥–Ω–æ, –≤–∞–∂–Ω—ã–µ –¥–µ—Ç–∞–ª–∏/—Ç–µ–∫—Å—Ç.")
            if part: vision_parts.append(f"–ö–∞–¥—Ä {i}:\n{part}")
        except Exception as ex:
            logger.warning("Vision frame %s error: %s", i, ex)
    out = ""
    if summary: out += "–°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è –ø–æ –∞—É–¥–∏–æ:\n" + summary + "\n\n"
    if vision_parts: out += "–í–∏–∑—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–∞–¥—Ä–æ–≤:\n" + "\n\n".join(vision_parts)
    await send_long_text(update, out or "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–∏–¥–µ–æ.")
except Exception as e:
    logger.exception("Video analyze error: %s", e)
    await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–∏–¥–µ–æ.")
def register_handlers(app_ptb: Application):
app_ptb.add_handler(CommandHandler("start", cmd_start))
app_ptb.add_handler(CommandHandler("help", cmd_help))
app_ptb.add_handler(CommandHandler("pricing", cmd_pricing))
app_ptb.add_handler(CommandHandler("buy", cmd_buy))
app_ptb.add_handler(CommandHandler("ref", cmd_ref))
app_ptb.add_handler(CommandHandler("status", cmd_status))
app_ptb.add_handler(CommandHandler("story", cmd_story))
app_ptb.add_handler(MessageHandler(filters.VOICE, handle_voice), group=0)
app_ptb.add_handler(MessageHandler(filters.AUDIO, handle_audio), group=0)
app_ptb.add_handler(MessageHandler(filters.VIDEO_NOTE, handle_video_note), group=0)
app_ptb.add_handler(MessageHandler(filters.VIDEO, handle_video), group=0)
app_ptb.add_handler(MessageHandler(filters.PHOTO, handle_photo), group=0)
app_ptb.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text), group=1)
def create_ptb_application() -> Application:
if not TELEGRAM_BOT_TOKEN: raise RuntimeError("TELEGRAM_BOT_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
app_ptb = Application.builder().token(TELEGRAM_BOT_TOKEN).concurrent_updates(True).build()
register_handlers(app_ptb); return app_ptb
@asynccontextmanager
async def lifespan(app: FastAPI):
global application
try:
    logger.info("Starting FastAPI lifespan init...")
    application = create_ptb_application()
    await application.initialize(); await application.start()
    if WEBHOOK_URL and TELEGRAM_WEBHOOK_SECRET:
        try:
            await application.bot.delete_webhook(drop_pending_updates=True)
        except Exception as e:
            logger.warning("delete_webhook warn: %s", e)
        await application.bot.set_webhook(url=WEBHOOK_URL, secret_token=TELEGRAM_WEBHOOK_SECRET,
            drop_pending_updates=True,
            allowed_updates=["message","edited_message","callback_query","chat_member","pre_checkout_query","channel_post","edited_channel_post","shipping_query"])
        logger.info("Webhook —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: %s", WEBHOOK_URL)
    else:
        logger.warning("PUBLIC_BASE_URL/TELEGRAM_WEBHOOK_SECRET –Ω–µ –∑–∞–¥–∞–Ω—ã ‚Äî –≤–µ–±—Ö—É–∫ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")
    yield
except Exception as e:
    logger.error("Startup error: %s", e, exc_info=True); raise
finally:
    try:
        if application:
            try:
                await application.bot.delete_webhook(drop_pending_updates=False)
            except Exception as e:
                logger.warning("delete_webhook at shutdown warn: %s", e)
            await application.stop(); await application.shutdown()
    except Exception as e:
        logger.error("Shutdown error: %s", e, exc_info=True)
app = FastAPI(title="Telegram Bot", version="1.1.0", lifespan=lifespan)
@app.get("/")
async def root():
return {"message": "Telegram Bot —Ä–∞–±–æ—Ç–∞–µ—Ç!", "status": "OK"}
@app.get("/health/live")
async def health_live():
return {"status": "ok"}
@app.get("/health/ready")
async def health_ready():
try:
    if not application: return JSONResponse({"status": "starting"}, status_code=503)
    me = await application.bot.get_me()
    return {"status": "ready", "bot_username": me.username}
except Exception as e:
    return JSONResponse({"status": "not_ready", "error": str(e)}, status_code=503)
@app.post("/telegram")
async def telegram_webhook(request: Request):
secret = request.headers.get("X-Telegram-Bot-Api-Secret-Token", "")
if TELEGRAM_WEBHOOK_SECRET and secret != TELEGRAM_WEBHOOK_SECRET:
    return JSONResponse({"ok": False, "error": "unauthorized"}, status_code=401)
try:
    data = await request.json()
    if not application:
        return JSONResponse({"ok": False, "error": "app not ready"}, status_code=503)
    update = Update.de_json(data, application.bot)
    if update:
        await application.process_update(update); return {"ok": True}
    return JSONResponse({"ok": False, "error": "invalid update"}, status_code=200)
except Exception:
    return JSONResponse({"ok": True})
if name == "main":
mode = os.getenv("MODE", "webhook").lower()
if mode == "polling":
    app_ptb = create_ptb_application()
    app_ptb.run_polling(allowed_updates=["message","edited_message","callback_query","chat_member","pre_checkout_query","channel_post","edited_channel_post","shipping_query"],
                        drop_pending_updates=True)
else:
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=int(os.getenv("PORT", "8000")), reload=False)
